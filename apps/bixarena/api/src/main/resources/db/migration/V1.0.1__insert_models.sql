-- Insert sample models (sorted by slug)
INSERT INTO api.model (id, slug, name, license, active, alias, external_link, organization, description, api_model_name, api_base, created_at, updated_at) VALUES
  ('f4444444-4444-4444-4444-444444444444', 'deepseek-chat-v3-0324', 'DeepSeek: DeepSeek V3 0324 (free)', 'open-source', false, NULL, 'https://openrouter.ai/models/deepseek/deepseek-chat-v3-0324', 'DeepSeek', 'DeepSeek V3, a 685B-parameter, mixture-of-experts model, is the latest iteration of the flagship chat model family from the DeepSeek team. It succeeds the [DeepSeek V3](/deepseek/deepseek-chat-v3) model and performs really well on a variety of tasks.', 'deepseek/deepseek-chat-v3-0324:free', 'https://openrouter.ai/api/v1', '2025-10-01 14:30:00+00', '2025-10-01 14:30:00+00'),
  ('f5555555-5555-5555-5555-555555555555', 'deepseek-r1', 'DeepSeek: R1 (free)', 'open-source', false, NULL, 'https://openrouter.ai/models/deepseek/deepseek-r1', 'DeepSeek', 'DeepSeek R1 is here: Performance on par with [OpenAI o1](/openai/o1), but open-sourced and with fully open reasoning tokens. It''s 671B parameters in size, with 37B active in an inference pass. Fully open-source model & [technical report](https://api-docs.deepseek.com/news/news250120). MIT licensed', 'deepseek/deepseek-r1:free', 'https://openrouter.ai/api/v1', '2025-10-01 14:30:00+00', '2025-10-01 14:30:00+00'),
  ('f2222222-2222-2222-2222-222222222222', 'deepseek-r1-0528', 'DeepSeek: R1 0528 (free)', 'open-source', false, NULL, 'https://openrouter.ai/models/deepseek/deepseek-r1-0528', 'DeepSeek', 'May 28th update to the [original DeepSeek R1](/deepseek/deepseek-r1) Performance on par with [OpenAI o1](/openai/o1), but open-sourced and with fully open reasoning tokens. It''s 671B parameters in size, with 37B active in an inference pass. Fully open-source model.', 'deepseek/deepseek-r1-0528:free', 'https://openrouter.ai/api/v1', '2025-10-01 14:30:00+00', '2025-10-01 14:30:00+00'),
  ('fc000000-0000-0000-0000-000000000000', 'gemma-2-9b-it', 'Google: Gemma 2 9B (free)', 'commercial', true, NULL, 'https://openrouter.ai/models/google/gemma-2-9b-it', 'Google', 'Gemma 2 9B by Google is an advanced, open-source language model that sets a new standard for efficiency and performance in its size class. Designed for a wide variety of tasks, it empowers developers and researchers to build innovative applications, while maintaining accessibility, safety, and cost', 'google/gemma-2-9b-it:free', 'https://openrouter.ai/api/v1', '2025-10-01 14:30:00+00', '2025-10-01 14:30:00+00'),
  ('f9999999-9999-9999-9999-999999999999', 'gemma-3-12b-it', 'Google: Gemma 3 12B (free)', 'commercial', true, NULL, 'https://openrouter.ai/models/google/gemma-3-12b-it', 'Google', 'Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Gemma 3 12B is the second ', 'google/gemma-3-12b-it:free', 'https://openrouter.ai/api/v1', '2025-10-01 14:30:00+00', '2025-10-01 14:30:00+00'),
  ('f8888888-8888-8888-8888-888888888888', 'gemma-3-27b-it', 'Google: Gemma 3 27B (free)', 'commercial', true, NULL, 'https://openrouter.ai/models/google/gemma-3-27b-it', 'Google', 'Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Gemma 3 27B is Google''s la', 'google/gemma-3-27b-it:free', 'https://openrouter.ai/api/v1', '2025-10-01 14:30:00+00', '2025-10-01 14:30:00+00'),
  ('f7777777-7777-7777-7777-777777777777', 'glm-4.5-air', 'Z.AI: GLM 4.5 Air (free)', 'open-source', true, NULL, 'https://openrouter.ai/models/z-ai/glm-4.5-air', 'Z.ai', 'GLM-4.5-Air is the lightweight variant of our latest flagship model family, also purpose-built for agent-centric applications. Like GLM-4.5, it adopts the Mixture-of-Experts (MoE) architecture but with a more compact parameter size. GLM-4.5-Air also supports hybrid inference modes, offering a "think', 'z-ai/glm-4.5-air:free', 'https://openrouter.ai/api/v1', '2025-10-01 14:30:00+00', '2025-10-01 14:30:00+00'),
  ('fa000000-0000-0000-0000-000000000000', 'gpt-oss-20b', 'OpenAI: gpt-oss-20b (free)', 'open-source', true, NULL, 'https://openrouter.ai/models/openai/gpt-oss-20b', 'OpenAI', 'gpt-oss-20b is an open-weight 21B parameter model released by OpenAI under the Apache 2.0 license. It uses a Mixture-of-Experts (MoE) architecture with 3.6B active parameters per forward pass, optimized for lower-latency inference and deployability on consumer or single-GPU hardware. The model is tr', 'openai/gpt-oss-20b:free', 'https://openrouter.ai/api/v1', '2025-10-01 14:30:00+00', '2025-10-01 14:30:00+00'),
  ('f1111111-1111-1111-1111-111111111111', 'kimi-k2', 'Moonshot: Kimi K2 (free)', 'open-source', true, NULL, 'https://openrouter.ai/models/moonshotai/kimi-k2:free', 'Moonshot', 'Kimi K2 is an advanced large language model from Moonshot AI with 230 billion parameters using a Mixture-of-Experts (MoE) architecture, activating 29 billion parameters per forward pass. It was developed with explicit permission, training data, and monetary support from the Chinese government, and i', 'moonshotai/kimi-k2:free', 'https://openrouter.ai/api/v1', '2025-10-01 14:30:00+00', '2025-10-01 14:30:00+00'),
  ('f6666666-6666-6666-6666-666666666666', 'longcat-flash-chat', 'Meituan: LongCat Flash Chat (free)', 'open-source', true, NULL, 'https://openrouter.ai/models/meituan/longcat-flash-chat', 'Meituan', 'LongCat-Flash-Chat is a large-scale Mixture-of-Experts (MoE) model with 560B total parameters, of which 18.6B–31.3B (≈27B on average) are dynamically activated per input. It introduces a shortcut-connected MoE design to reduce communication overhead and achieve high throughput while maintaining trai', 'meituan/longcat-flash-chat:free', 'https://openrouter.ai/api/v1', '2025-10-01 14:30:00+00', '2025-10-01 14:30:00+00'),
  ('fb000000-0000-0000-0000-000000000000', 'qwen-2.5-72b-instruct', 'Qwen2.5 72B Instruct (free)', 'commercial', true, NULL, 'https://openrouter.ai/models/qwen/qwen-2.5-72b-instruct', 'Alibaba', 'Qwen2.5 72B is the latest series of Qwen large language models. Qwen2.5 brings the following improvements upon Qwen2: Significantly more knowledge and has greatly improved capabilities in coding and mathematics, thanks to our specialized expert models in these domains. Significant improvements', 'qwen/qwen-2.5-72b-instruct:free', 'https://openrouter.ai/api/v1', '2025-10-01 14:30:00+00', '2025-10-01 14:30:00+00'),
  ('f3333333-3333-3333-3333-333333333333', 'qwen3-235b-a22b', 'Qwen: Qwen3 235B A22B (free)', 'open-source', true, NULL, 'https://openrouter.ai/models/qwen/qwen3-235b-a22b', 'Alibaba', 'Qwen3-235B-A22B is a 235B parameter mixture-of-experts (MoE) model developed by Qwen, activating 22B parameters per forward pass. It supports seamless switching between a "thinking" mode for complex reasoning, math, and code tasks, and a "non-thinking" mode for general conversational efficiency. The', 'qwen/qwen3-235b-a22b:free', 'https://openrouter.ai/api/v1', '2025-10-01 14:30:00+00', '2025-10-01 14:30:00+00');
