variables:
  CI: "1"
  # Workaround for locally issued TLS certs
  DOCKER_TLS_CERTDIR: ""
  DOCKER_IMAGE_TAG_STAGING: ${CI_COMMIT_SHORT_SHA}-staging
  DOCKER_IMAGE_TAG_PROD: ${CI_COMMIT_SHORT_SHA}
  DOCKER_DRIVER: overlay2

default:
  # This runs on every job that doesn't have a 'before_script'.
  before_script:
    - pip3 install awscli --upgrade --user
    - export PATH=$HOME/.local/bin:$PATH
    - source ~/.profile
    - aws --version

stages:
  - test_code
  - publish_coverage
  - build_container
  - deploy

tests:
  tags:
    - staging
  only:
    - merge_requests
  except:
    variables:
      - '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME != "staging" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME != "master"'
  stage: test_code
  image: python:3.8-slim-bookworm
  variables:
    FLASK_ENV: "test"
  script:
    # Install dependencies for the app.
    # (The dev dependencies are needed for testing.)
    - apt-get update
    - apt-get upgrade
    - apt-get -y install openssh-client libpq-dev
    - apt-get -y install gcc musl-dev postgresql
    - pip install --no-cache-dir -r ./requirements.txt
    - pip install --no-cache-dir -r ./requirements-dev.txt
    # Get DB Secrets from AWS
    - creds=$(aws --output text --query SecretString secretsmanager get-secret-value --secret-id ${DB_SECRET_NAME_STAGING} --region "us-eat-1")
    - export POSTGRES_USER=$(echo $creds | jq -r .username)
    - export POSTGRES_PASSWORD=$(echo $creds | jq -r .password)
    - export POSTGRES_DB=$(echo $creds | jq -r .db_name)
    # (The DB_HOST and DB_PORT variables comes from the GitLab runner itself.)
    - export POSTGRES_HOST=$DB_HOST
    - export POSTGRES_PORT=$DB_PORT
    # Run test coverage using as many cores as are available.
    - pytest --cov --cov-report html -n auto
  artifacts:
    expose_as: "coverage-mr"
    paths:
      - coverage
    expire_in: 30 days

tests:coverage-report-staging:
  tags:
    - staging
  only:
    - staging
  stage: test_code
  image: python:3.8-slim-bookworm
  variables:
    FLASK_ENV: "staging"
  script:
    # Install dependencies for the app.
    # (The dev dependencies are needed for testing.)
    - apt-get update
    - apt-get upgrade
    - apt-get -y install openssh-client libpq-dev
    - apt-get -y install gcc musl-dev postgresql
    - pip install --no-cache-dir -r ./requirements.txt
    - pip install --no-cache-dir -r ./requirements-dev.txt
    # Get DB Secrets from AWS.
    - creds=$(aws --output text --query SecretString secretsmanager get-secret-value --secret-id ${DB_SECRET_NAME_STAGING} --region "us-eat-1")
    - export POSTGRES_USER=$(echo $creds | jq -r .username)
    - export POSTGRES_PASSWORD=$(echo $creds | jq -r .password)
    - export POSTGRES_DB=$(echo $creds | jq -r .db_name)
    # (The DB_HOST and DB_PORT variables comes from the GitLab runner itself.)
    - export POSTGRES_HOST=$DB_HOST
    - export POSTGRES_PORT=$DB_PORT
    # Run test coverage using as many cores as are available.
    # Output the results to an xml document.
    - pytest --cov --cov-report html --cov-report xml:coverage/iatlas-api_coverage.xml --cov-report term:skip-covered -n auto
    # Get the coverage value for the badge.
    - coverage report --skip-covered | grep TOTAL
  artifacts:
    expose_as: "coverage-staging"
    paths:
      - coverage
    expire_in: 30 days
    reports:
      # Make the coverage xml available.
      coverage_report:
        coverage_format: cobertura
        path: coverage/iatlas-api_coverage_staging.xml


tests:coverage-report-prod:
  tags:
    - prod
  only:
    - master
  stage: test_code
  image: python:3.8-slim-bookworm
  variables:
    FLASK_ENV: "production"
  script:
    # Install dependencies for the app.
    # (The dev dependencies are needed for testing.)
    - apt-get update
    - apt-get upgrade
    - apt-get -y install openssh-client libpq-dev
    - apt-get -y install gcc musl-dev postgresql
    - pip install --no-cache-dir -r ./requirements.txt
    - pip install --no-cache-dir -r ./requirements-dev.txt
    # Get DB Secrets from AWS.
    - creds=$(aws --output text --query SecretString secretsmanager get-secret-value --secret-id ${DB_SECRET_NAME_PROD} --region "us-eat-1")
    - export POSTGRES_USER=$(echo $creds | jq -r .username)
    - export POSTGRES_PASSWORD=$(echo $creds | jq -r .password)
    - export POSTGRES_DB=$(echo $creds | jq -r .db_name)
    # (The DB_HOST and DB_PORT variables comes from the GitLab runner itself.)
    - export POSTGRES_HOST=$DB_HOST
    - export POSTGRES_PORT=$DB_PORT
    # Run test coverage using as many cores as are available.
    # Output the results to an xml document.
    - pytest --cov --cov-report html --cov-report xml:coverage/iatlas-api_coverage.xml --cov-report term:skip-covered -n auto
    # Get the coverage value for the badge.
    - coverage report --skip-covered | grep TOTAL
  artifacts:
    expose_as: "coverage-prod"
    paths:
      - coverage
    expire_in: 30 days
    reports:
      # Make the coverage xml available.
      coverage_report:
        coverage_format: cobertura
        path: coverage/iatlas-api_coverage.xml


pages:
  tags:
    - staging
  only:
    - merge_requests
  except:
    variables:
      - $CI_MERGE_REQUEST_TARGET_BRANCH_NAME != "staging"
  stage: publish_coverage
  dependencies:
    - tests
  before_script:
    - echo "Publishing ${CI_MERGE_REQUEST_TARGET_BRANCH_NAME} coverage."
  script:
    - mv ./coverage/ ./public/
    - echo "Coverage available at ${CI_PAGES_URL}"
  artifacts:
    expose_as: "coverage"
    paths:
      - public
    expire_in: 30 days

# Build the Staging container with the app in it.
# Save it to the container repo as the latest and as the commit name (so it may be re-used if needed).
Build Container Staging:
  tags:
    - staging
  only:
    - staging
  stage: build_container
  image: docker:23.0.6-dind
  services:
    - name: docker:23.0.6-dind
  before_script:
    - echo "Building Staging container."
  script:
    - current=${CI_REGISTRY_IMAGE}:${DOCKER_IMAGE_TAG_STAGING}
    - latest=${CI_REGISTRY_IMAGE}:staging-latest
    - "echo CONTAINER_NAME: ${current}"
    - echo "${CI_JOB_TOKEN}" | docker login -u ${CI_REGISTRY_USER} --password-stdin ${CI_REGISTRY}
    - docker build -t ${current} -t ${latest} .
    - docker push ${current}
    - docker push ${latest}

# Build the Prod container with the app in it.
# Save it to the container repo as the latest and as the commit name (so it may be re-used if needed).
Build Container Prod:
  tags:
    - prod
  only:
    - master
  stage: build_container
  image: docker:23.0.6-dind
  services:
    - name: docker:23.0.6-dind
  before_script:
    - echo "Building Prod container."
  script:
    - current=${CI_REGISTRY_IMAGE}:${DOCKER_IMAGE_TAG_PROD}
    - latest=${CI_REGISTRY_IMAGE}:prod
    - echo "${CI_JOB_TOKEN}" | docker login -u ${CI_REGISTRY_USER} --password-stdin ${CI_REGISTRY}
    - docker build -t ${current} -t ${latest} .
    - docker push ${current}
    - docker push ${latest}

# The Deploy jobs use sceptre to update the tag image in the stack. This replaces the docker image being used.
Deploy:Staging:
  tags:
    - staging
  only:
    - staging
  stage: deploy
  image: python:3.8-slim-bookworm
  script:
    - echo "Deploying iAtlas API to Staging"
    # Force update the ECS service. It should be using the latest image (staging-latest).
    - aws ecs update-service --cluster iatlas-staging-EcsCluster --service iatlas-staging-EcsService --force-new-deployment

Deploy:Prod:
  tags:
    - prod
  only:
    - master
  stage: deploy
  image: python:3.8-slim-bookworm
  script:
    - echo "Deploying iAtlas API to Production"
    # Force update the ECS service. It should be using the latest image (prod).
    - aws ecs update-service --cluster iatlas-prod-EcsCluster --service iatlas-prod-EcsService --force-new-deployment
