variables:
  CI: "1"
  # Workaround for locally issued TLS certs
  DOCKER_TLS_CERTDIR: ""
  CONTAINER_LABEL: iatlas-api
  DOCKER_IMAGE_TAG_STAGING: ${CI_COMMIT_SHORT_SHA}-staging
  DOCKER_IMAGE_TAG_PROD: ${CI_COMMIT_SHORT_SHA}

default:
  # This runs on every job that doesn't have a 'before_script'.
  before_script:
    # Install glibc compatibility for alpine and install aws (also installs curl, unzip, and jq)
    - "GLIBC_VER=2.31-r0"
    - "apk add --no-cache binutils curl unzip jq"
    - "curl -sL https://alpine-pkgs.sgerrand.com/sgerrand.rsa.pub -o /etc/apk/keys/sgerrand.rsa.pub"
    - "curl -sLO https://github.com/sgerrand/alpine-pkg-glibc/releases/download/${GLIBC_VER}/glibc-${GLIBC_VER}.apk"
    - "curl -sLO https://github.com/sgerrand/alpine-pkg-glibc/releases/download/${GLIBC_VER}/glibc-bin-${GLIBC_VER}.apk"
    - "apk add --no-cache glibc-${GLIBC_VER}.apk glibc-bin-${GLIBC_VER}.apk"
    - "curl -sL https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip -o awscliv2.zip"
    - "unzip awscliv2.zip"
    - "aws/install"
    - "rm -rf awscliv2.zip \
      aws \
      /usr/local/aws-cli/v2/*/dist/aws_completer \
      /usr/local/aws-cli/v2/*/dist/awscli/data/ac.index \
      /usr/local/aws-cli/v2/*/dist/awscli/examples"
    - "apk --no-cache del binutils"
    - "rm glibc-${GLIBC_VER}.apk"
    - "rm glibc-bin-${GLIBC_VER}.apk"
    - "rm -rf /var/cache/apk/*"
    - "aws --version"
    # Create the AWS credentials and config files.
    - "mkdir ~/.aws"
    - 'echo -e "[default]\naws_access_key_id = ${AWS_ACCESS_KEY_ID}\naws_secret_access_key = ${AWS_SECRET_ACCESS_KEY}\nregion = ${AWS_DEFAULT_REGION}" >> ~/.aws/credentials'
    - 'echo -e "[default]\nregion = $AWS_DEFAULT_REGION\noutput = json" >> ~/.aws/config'

stages:
  - test_code
  - publish_coverage
  - build_container
  - deploy

tests:
  only:
    - merge_requests
  except:
    variables:
      - '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME != "staging" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME != "MASTER"'
  stage: test_code
  image: python:3.8-alpine
  variables:
    DB_SECRET_NAME: ${DB_SECRET_NAME_STAGING}
    FLASK_ENV: "test"
    # The environment variables used to populate the job scoped environment variables (DB_HOST_STAGING and DB_PORT_STAGING) are populated in the GitLab Runner in AWS
    POSTGRES_HOST: ${DB_HOST_STAGING}
    POSTGRES_PORT: ${DB_PORT_STAGING}
  script:
    # Install dependencies for the app.
    # (The dev dependencies are needed for testing.)
    - "apk add --no-cache openssh libpq"
    - "apk add --no-cache --virtual .build-deps gcc musl-dev postgresql-dev linux-headers"
    - "pip install --no-cache-dir -r ./requirements.txt"
    - "pip install --no-cache-dir -r ./requirements-dev.txt"
    - "apk del --no-cache .build-deps"
    # Get DB Secrets from AWS
    - "creds=$(aws --region ${AWS_DEFAULT_REGION} --output text --query SecretString secretsmanager get-secret-value --secret-id ${DB_SECRET_NAME})"
    - "export POSTGRES_USER=$(echo $creds | jq -r .username)"
    - "export POSTGRES_PASSWORD=$(echo $creds | jq -r .password)"
    - "export POSTGRES_DB=$(echo $creds | jq -r .db_name)"
    # Run test coverage using as many cores as are available.
    - pytest --cov --cov-report html -n auto
  artifacts:
    expose_as: "coverage-mr"
    paths:
      - coverage
    expire_in: 30 days

tests:coverage-report-staging:
  only:
    - staging
  stage: test_code
  image: python:3.8-alpine
  variables:
    DB_SECRET_NAME: ${DB_SECRET_NAME_STAGING}
    FLASK_ENV: "staging"
    # The environment variables used to populate the job scoped environment variables (DB_HOST_STAGING and DB_PORT_STAGING) are populated in the GitLab Runner in AWS.
    POSTGRES_HOST: ${DB_HOST_STAGING}
    POSTGRES_PORT: ${DB_PORT_STAGING}
  script:
    # Install dependencies for the app.
    # (The dev dependencies are needed for testing.)
    - "apk add --no-cache openssh libpq"
    - "apk add --no-cache --virtual .build-deps gcc musl-dev postgresql-dev linux-headers"
    - "pip install --no-cache-dir -r ./requirements.txt"
    - "pip install --no-cache-dir -r ./requirements-dev.txt"
    - "apk del --no-cache .build-deps"
    # Get DB Secrets from AWS.
    - "creds=$(aws --region ${AWS_DEFAULT_REGION} --output text --query SecretString secretsmanager get-secret-value --secret-id ${DB_SECRET_NAME})"
    - "export POSTGRES_USER=$(echo $creds | jq -r .username)"
    - "export POSTGRES_PASSWORD=$(echo $creds | jq -r .password)"
    - "export POSTGRES_DB=$(echo $creds | jq -r .db_name)"
    # Run test coverage using as many cores as are available.
    # Output the results to an xml document.
    - pytest --cov --cov-report html --cov-report xml:coverage/iatlas-api_coverage.xml --cov-report term:skip-covered -n auto
    # Get the coverage value for the badge.
    - coverage report --skip-covered | grep TOTAL
  artifacts:
    expose_as: "coverage-staging"
    paths:
      - coverage
    expire_in: 30 days
    reports:
      # Make the coverage xml available.
      cobertura: "coverage/iatlas-api_coverage_staging.xml"

tests:coverage-report-prod:
  only:
    - master
  stage: test_code
  image: python:3.8-alpine
  variables:
    FLASK_ENV: "production"
    # The environment variables used to populate the job scoped environment variables (DB_HOST_PROD, DB_PORT_PROD, and DB_SECRET_NAME_PROD) are populated in the GitLab Runner in AWS.
    POSTGRES_HOST: ${DB_HOST_PROD}
    POSTGRES_PORT: ${DB_PORT_PROD}
    DB_SECRET_NAME: ${DB_SECRET_NAME_PROD}
  script:
    # Install dependencies for the app.
    # (The dev dependencies are needed for testing.)
    - "apk add --no-cache openssh libpq"
    - "apk add --no-cache --virtual .build-deps gcc musl-dev postgresql-dev linux-headers"
    - "pip install --no-cache-dir -r ./requirements.txt"
    - "pip install --no-cache-dir -r ./requirements-dev.txt"
    - "apk del --no-cache .build-deps"
    # Get DB Secrets from AWS.
    - "creds=$(aws --region ${AWS_DEFAULT_REGION} --output text --query SecretString secretsmanager get-secret-value --secret-id ${DB_SECRET_NAME})"
    - "export POSTGRES_USER=$(echo $creds | jq -r .username)"
    - "export POSTGRES_PASSWORD=$(echo $creds | jq -r .password)"
    - "export POSTGRES_DB=$(echo $creds | jq -r .db_name)"
    # Run test coverage using as many cores as are available.
    # Output the results to an xml document.
    - pytest --cov --cov-report html --cov-report xml:coverage/iatlas-api_coverage.xml --cov-report term:skip-covered -n auto
    # Get the coverage value for the badge.
    - coverage report --skip-covered | grep TOTAL
  artifacts:
    expose_as: "coverage-prod"
    paths:
      - coverage
    expire_in: 30 days
    reports:
      # Make the coverage xml available.
      cobertura: "coverage/iatlas-api_coverage.xml"

pages:
  only:
    - merge_requests
  except:
    variables:
      - $CI_MERGE_REQUEST_TARGET_BRANCH_NAME != "staging"
  stage: publish_coverage
  dependencies:
    - tests
  before_script:
    - "echo Publishing ${CI_MERGE_REQUEST_TARGET_BRANCH_NAME} coverage."
  script:
    - "mv ./coverage/ ./public/"
    - 'echo "Coverage available at ${CI_PAGES_URL}"'
  artifacts:
    expose_as: "coverage"
    paths:
      - public
    expire_in: 30 days

# Build the Staging container with the app in it.
# Save it to the container repo as the latest and as the commit name (so it may be re-used if needed).
Build Container Staging:
  only:
    - staging
  stage: build_container
  image: docker:19.03.1-dind
  services:
    - name: docker:19.03.1-dind
  before_script:
    - "echo Building Staging container."
  script:
    - current=${CI_REGISTRY_IMAGE}:${DOCKER_IMAGE_TAG_STAGING}
    - latest=${CI_REGISTRY_IMAGE}:staging-latest
    - "echo CONTAINER_NAME: ${current}"
    - echo "${CI_JOB_TOKEN}" | docker login -u ${CI_REGISTRY_USER} --password-stdin ${CI_REGISTRY}
    - "docker build -t ${current} -t ${latest} ."
    - "docker push ${current}"
    - "docker push ${latest}"

# Build the Prod container with the app in it.
# Save it to the container repo as the latest and as the commit name (so it may be re-used if needed).
Build Container Prod:
  only:
    - master
  stage: build_container
  image: docker:19.03.1-dind
  services:
    - name: docker:19.03.1-dind
  before_script:
    - "echo Building Prod container."
  script:
    - current=${CI_REGISTRY_IMAGE}:${DOCKER_IMAGE_TAG_PROD}
    - latest=${CI_REGISTRY_IMAGE}:staging-latest
    - echo "${CI_JOB_TOKEN}" | docker login -u ${CI_REGISTRY_USER} --password-stdin ${CI_REGISTRY}
    - "docker build -t ${current} -t ${latest} ."
    - "docker push ${current}"
    - "docker push ${latest}"

# The Deploy job uses
Deploy:Staging:
  only:
    - staging
  stage: deploy
  image: python:3.8-alpine
  variables:
    # The AWS Environment Variables to specify configuration options and credentials for the aws cli.
    AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
    AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
    AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
    DOCKER_IMAGE_TAG: ${DOCKER_IMAGE_TAG_STAGING}
    GITLAB_REG_TOKEN: ${GITLAB_REG_TOKEN}
    TRAVIS_BRANCH: "staging"
  script:
    - "echo Deploying iAtlas API to Staging (image: ${DOCKER_IMAGE_TAG})"
    - "sceptre_stack_file=staging/iatlas-api.yaml"
    # Ensure git is available.
    - "apk add --no-cache git"
    # Get the Sceptre scripts.
    - "git clone -b feature/ecs https://github.com/generalui/iAtlas-infra.git"
    - "cd iAtlas-infra"
    # Ensure Sceptre is available and can handle !ssm.
    - "pip install --no-cache-dir sceptre sceptre-ssm-resolver"
    # Get the current status of the API stack.
    - sceptre_status=$(sceptre --var "region=${AWS_DEFAULT_REGION}" status ${sceptre_stack_file} | jq '."staging/iatlas-api"')
    - "echo ${sceptre_status}"
    # If there was an issue with the previous build and the build was rolled back, delete the stack.
    - if [ ${sceptre_status} == '"ROLLBACK_COMPLETE"' ] || [ ${sceptre_status} == '"CREATE_FAILED"' ]; then sceptre --var "region=${AWS_DEFAULT_REGION}" delete -y ${sceptre_stack_file}; fi
    # Get the current status of the API stack.
    - sceptre_status=$(sceptre --var "region=${AWS_DEFAULT_REGION}" status ${sceptre_stack_file} | jq '."staging/iatlas-api"')
    - "echo ${sceptre_status}"
    # If there is an existing stack, update the stack.
    - if [ ${sceptre_status} == '"UPDATE_COMPLETE"' ] || [ ${sceptre_status} == '"CREATE_COMPLETE"' ]; then sceptre --var "region=${AWS_DEFAULT_REGION}" update -y ${sceptre_stack_file}; fi
    # Get the current status of the API stack.
    - sceptre_status=$(sceptre --var "region=${AWS_DEFAULT_REGION}" status ${sceptre_stack_file} | jq '."staging/iatlas-api"')
    - "echo ${sceptre_status}"
    # If there is no stack, create the stack.
    - if [ ${sceptre_status} == '"PENDING"' ]; then sceptre --var "region=${AWS_DEFAULT_REGION}" create -y ${sceptre_stack_file}; fi
    # Get the current status of the API stack.
    - sceptre_status=$(sceptre --var "region=${AWS_DEFAULT_REGION}" status ${sceptre_stack_file} | jq '."staging/iatlas-api"')
    - "echo ${sceptre_status}"
    # If the update succeeded or a first build succeeded, end the job, otherwise, fail the job.
    - if [ ${sceptre_status} == '"UPDATE_COMPLETE"' ] || [ ${sceptre_status} == '"CREATE_COMPLETE"' ]; then exit 0; else exit 1; fi

Deploy:Prod:
  only:
    - master
  stage: deploy
  image: python:3.8-alpine
  variables:
    # The AWS Environment Variables to specify configuration options and credentials for the aws cli.
    AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
    AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
    AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
    DOCKER_IMAGE_TAG: ${DOCKER_IMAGE_TAG_PROD}
    TRAVIS_BRANCH: "master"
  script:
    - "echo Deploying iAtlas API to Production (image: ${DOCKER_IMAGE_TAG})"
    - "sceptre_stack_file=prod/iatlas-api.yaml"
    # Ensure git is available.
    - "apk add --no-cache git"
    # Get the Sceptre scripts.
    - "git clone -b feature/ecs https://github.com/generalui/iAtlas-infra.git"
    - "cd iAtlas-infra"
    # Ensure Sceptre is available and can handle !ssm.
    - "pip install --no-cache-dir sceptre sceptre-ssm-resolver"
    # Get the current status of the API stack.
    - sceptre_status=$(sceptre --var "region=${AWS_DEFAULT_REGION}" status ${sceptre_stack_file} | jq '."prod/iatlas-api"')
    - "echo ${sceptre_status}"
    # If there was an issue with the previous build and the build was rolled back, delete the stack.
    - if [ ${sceptre_status} == '"ROLLBACK_COMPLETE"' ] || [ ${sceptre_status} == '"CREATE_FAILED"' ]; then sceptre --var "region=${AWS_DEFAULT_REGION}" delete -y ${sceptre_stack_file}; fi
    # Get the current status of the API stack.
    - sceptre_status=$(sceptre --var "region=${AWS_DEFAULT_REGION}" status ${sceptre_stack_file} | jq '."prod/iatlas-api"')
    - "echo ${sceptre_status}"
    # If there is an existing stack, update the stack.
    - if [ ${sceptre_status} == '"UPDATE_COMPLETE"' ] || [ ${sceptre_status} == '"CREATE_COMPLETE"' ]; then sceptre --var "region=${AWS_DEFAULT_REGION}" update -y ${sceptre_stack_file}; fi
    # Get the current status of the API stack.
    - sceptre_status=$(sceptre --var "region=${AWS_DEFAULT_REGION}" status ${sceptre_stack_file} | jq '."prod/iatlas-api"')
    - "echo ${sceptre_status}"
    # If there is no stack, create the stack.
    - if [ ${sceptre_status} == '"PENDING"' ]; then sceptre --var "region=${AWS_DEFAULT_REGION}" create -y ${sceptre_stack_file}; fi
    # Get the current status of the API stack.
    - sceptre_status=$(sceptre --var "region=${AWS_DEFAULT_REGION}" status ${sceptre_stack_file} | jq '."prod/iatlas-api"')
    - "echo ${sceptre_status}"
    # If the update succeeded or a first build succeeded, end the job, otherwise, fail the job.
    - if [ ${sceptre_status} == '"UPDATE_COMPLETE"' ] || [ ${sceptre_status} == '"CREATE_COMPLETE"' ]; then exit 0; else exit 1; fi
