variables:
  CI: "1"
  # Workaround for locally issued TLS certs
  DOCKER_TLS_CERTDIR: ""
  DOCKER_IMAGE_TAG_STAGING: ${CI_COMMIT_SHORT_SHA}-staging
  DOCKER_IMAGE_TAG_PROD: ${CI_COMMIT_SHORT_SHA}

default:
  # This runs on every job that doesn't have a 'before_script'.
  before_script:
    # Install aws cli (also installs binutils, jq, unzip, and wget) - (Running on Alpine)
    - GLIBC_VER=2.34.r0
    - apk add --force-overwrite --no-cache binutils curl jq unzip
    # Install glibc compatibility for alpine (Needed for AWS cli v2)
    - curl -sL https://alpine-pkgs.sgerrand.com/sgerrand.rsa.pub -o /etc/apk/keys/sgerrand.rsa.pub
    - curl -sLO https://github.com/sgerrand/alpine-pkg-glibc/releases/download/${GLIBC_VER}/glibc-${GLIBC_VER}.apk
    - curl -sLO https://github.com/sgerrand/alpine-pkg-glibc/releases/download/${GLIBC_VER}/glibc-bin-${GLIBC_VER}.apk
    - apk add --no-cache glibc-${GLIBC_VER}.apk glibc-bin-${GLIBC_VER}.apk
    # Install AWS cli v2
    - curl -sL https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip -o awscliv2.zip
    - unzip awscliv2.zip
    - aws/install
    - "rm -rf awscliv2.zip \
      aws \
      /usr/local/aws-cli/v2/*/dist/aws_completer \
      /usr/local/aws-cli/v2/*/dist/awscli/data/ac.index \
      /usr/local/aws-cli/v2/*/dist/awscli/examples"
    - apk --no-cache del binutils curl unzip
    - rm glibc-${GLIBC_VER}.apk
    - rm glibc-bin-${GLIBC_VER}.apk
    - rm -rf /var/cache/apk/*
    - aws --version

stages:
  - test_code
  - publish_coverage
  - build_container
  - deploy

tests:
  tags:
    - staging
  only:
    - merge_requests
  except:
    variables:
      - '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME != "staging" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME != "master"'
  stage: test_code
  image: python:3.8-alpine
  variables:
    FLASK_ENV: "test"
  script:
    # Install dependencies for the app.
    # (The dev dependencies are needed for testing.)
    - apk add --no-cache openssh libpq
    - apk add --no-cache --virtual .build-deps gcc musl-dev postgresql-dev linux-headers
    - pip install --no-cache-dir -r ./requirements.txt
    - pip install --no-cache-dir -r ./requirements-dev.txt
    - apk del --no-cache .build-deps
    # Get DB Secrets from AWS
    - creds=$(aws --output text --query SecretString secretsmanager get-secret-value --secret-id ${DB_SECRET_NAME_STAGING})
    - export POSTGRES_USER=$(echo $creds | jq -r .username)
    - export POSTGRES_PASSWORD=$(echo $creds | jq -r .password)
    - export POSTGRES_DB=$(echo $creds | jq -r .db_name)
    # (The DB_HOST and DB_PORT variables comes from the GitLab runner itself.)
    - export POSTGRES_HOST=$DB_HOST
    - export POSTGRES_PORT=$DB_PORT
    # Run test coverage using as many cores as are available.
    - pytest --cov --cov-report html -n auto
  artifacts:
    expose_as: "coverage-mr"
    paths:
      - coverage
    expire_in: 30 days

tests:coverage-report-staging:
  tags:
    - staging
  only:
    - staging
  stage: test_code
  image: python:3.8-alpine
  variables:
    FLASK_ENV: "staging"
  script:
    # Install dependencies for the app.
    # (The dev dependencies are needed for testing.)
    - apk add --no-cache openssh libpq
    - apk add --no-cache --virtual .build-deps gcc musl-dev postgresql-dev linux-headers
    - pip install --no-cache-dir -r ./requirements.txt
    - pip install --no-cache-dir -r ./requirements-dev.txt
    - apk del --no-cache .build-deps
    # Get DB Secrets from AWS.
    - creds=$(aws --output text --query SecretString secretsmanager get-secret-value --secret-id ${DB_SECRET_NAME_STAGING})
    - export POSTGRES_USER=$(echo $creds | jq -r .username)
    - export POSTGRES_PASSWORD=$(echo $creds | jq -r .password)
    - export POSTGRES_DB=$(echo $creds | jq -r .db_name)
    # (The DB_HOST and DB_PORT variables comes from the GitLab runner itself.)
    - export POSTGRES_HOST=$DB_HOST
    - export POSTGRES_PORT=$DB_PORT
    # Run test coverage using as many cores as are available.
    # Output the results to an xml document.
    - pytest --cov --cov-report html --cov-report xml:coverage/iatlas-api_coverage.xml --cov-report term:skip-covered -n auto
    # Get the coverage value for the badge.
    - coverage report --skip-covered | grep TOTAL
  artifacts:
    expose_as: "coverage-staging"
    paths:
      - coverage
    expire_in: 30 days
    reports:
      coverage_report:
        coverage_format: cobertura
        path: build/cobertura.xml


tests:coverage-report-prod:
  tags:
    - prod
  only:
    - master
  stage: test_code
  image: python:3.8-alpine
  variables:
    FLASK_ENV: "production"
  script:
    # Install dependencies for the app.
    # (The dev dependencies are needed for testing.)
    - apk add --no-cache openssh libpq
    - apk add --no-cache --virtual .build-deps gcc musl-dev postgresql-dev linux-headers
    - pip install --no-cache-dir -r ./requirements.txt
    - pip install --no-cache-dir -r ./requirements-dev.txt
    - apk del --no-cache .build-deps
    # Get DB Secrets from AWS.
    - creds=$(aws --output text --query SecretString secretsmanager get-secret-value --secret-id ${DB_SECRET_NAME_PROD})
    - export POSTGRES_USER=$(echo $creds | jq -r .username)
    - export POSTGRES_PASSWORD=$(echo $creds | jq -r .password)
    - export POSTGRES_DB=$(echo $creds | jq -r .db_name)
    # (The DB_HOST and DB_PORT variables comes from the GitLab runner itself.)
    - export POSTGRES_HOST=$DB_HOST
    - export POSTGRES_PORT=$DB_PORT
    # Run test coverage using as many cores as are available.
    # Output the results to an xml document.
    - pytest --cov --cov-report html --cov-report xml:coverage/iatlas-api_coverage.xml --cov-report term:skip-covered -n auto
    # Get the coverage value for the badge.
    - coverage report --skip-covered | grep TOTAL
  artifacts:
    expose_as: "coverage-prod"
    paths:
      - coverage
    expire_in: 30 days
    reports:
      coverage_report:
        coverage_format: cobertura
        path: build/cobertura.xml


pages:
  tags:
    - staging
  only:
    - merge_requests
  except:
    variables:
      - $CI_MERGE_REQUEST_TARGET_BRANCH_NAME != "staging"
  stage: publish_coverage
  dependencies:
    - tests
  before_script:
    - echo "Publishing ${CI_MERGE_REQUEST_TARGET_BRANCH_NAME} coverage."
  script:
    - mv ./coverage/ ./public/
    - echo "Coverage available at ${CI_PAGES_URL}"
  artifacts:
    expose_as: "coverage"
    paths:
      - public
    expire_in: 30 days

# Build the Staging container with the app in it.
# Save it to the container repo as the latest and as the commit name (so it may be re-used if needed).
Build Container Staging:
  tags:
    - staging
  only:
    - staging
  stage: build_container
  image: docker:19.03.1-dind
  services:
    - name: docker:19.03.1-dind
  before_script:
    - echo "Building Staging container."
  script:
    - current=${CI_REGISTRY_IMAGE}:${DOCKER_IMAGE_TAG_STAGING}
    - latest=${CI_REGISTRY_IMAGE}:staging-latest
    - "echo CONTAINER_NAME: ${current}"
    - echo "${CI_JOB_TOKEN}" | docker login -u ${CI_REGISTRY_USER} --password-stdin ${CI_REGISTRY}
    - docker build -t ${current} -t ${latest} .
    - docker push ${current}
    - docker push ${latest}

# Build the Prod container with the app in it.
# Save it to the container repo as the latest and as the commit name (so it may be re-used if needed).
Build Container Prod:
  tags:
    - prod
  only:
    - master
  stage: build_container
  image: docker:19.03.1-dind
  services:
    - name: docker:19.03.1-dind
  before_script:
    - echo "Building Prod container."
  script:
    - current=${CI_REGISTRY_IMAGE}:${DOCKER_IMAGE_TAG_PROD}
    - latest=${CI_REGISTRY_IMAGE}:prod
    - echo "${CI_JOB_TOKEN}" | docker login -u ${CI_REGISTRY_USER} --password-stdin ${CI_REGISTRY}
    - docker build -t ${current} -t ${latest} .
    - docker push ${current}
    - docker push ${latest}

# The Deploy jobs use sceptre to update the tag image in the stack. This replaces the docker image being used.
Deploy:Staging:
  tags:
    - staging
  only:
    - staging
  stage: deploy
  image: python:3.8-alpine
  script:
    - echo "Deploying iAtlas API to Staging"
    # Force update the ECS service. It should be using the latest image (staging-latest).
    - aws ecs update-service --cluster iatlas-staging-EcsCluster --service iatlas-staging-EcsService --force-new-deployment

Deploy:Prod:
  tags:
    - prod
  only:
    - master
  stage: deploy
  image: python:3.8-alpine
  script:
    - echo "Deploying iAtlas API to Production"
    # Force update the ECS service. It should be using the latest image (prod).
    - aws ecs update-service --cluster iatlas-prod-EcsCluster --service iatlas-prod-EcsService --force-new-deployment
